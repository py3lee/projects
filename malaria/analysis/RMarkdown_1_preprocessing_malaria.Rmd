---
title: "Malaria datasets - Preprocessing in R"

output: 
 html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The initial exploration and sanity of the 3 datasets was done in python, with every step detailed in the jupyter notebook `Python_1_EDA_malaria.ipynb`.   
This current Rmarkdown file will detail the same preprocessing steps as listed in the python jupyter notebook, but implemented in R instead. 

# Background

## What is malaria? 

[Malaria is a vector-borne parasitic tropical disease, transmitted by the bite of the female *Anopheles* mosquito](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(18)30324-6/fulltext).  Patients infected by one of the Plasmodium species can experience severe illness and death.


# Primary problem statement 

Is there any observable trend on the incidence of malaria and malaria-related deaths over the years? 

## Dataset 
Data Source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13  

3 Datasets:

- malaria_inc.csv - Malaria incidence by country for all ages across the world across time
- malaria_deaths.csv - Malaria deaths by country for all ages across the world and time.
- malaria_deaths_age.csv - Malaria deaths by age across the world and time.

note: unable to trace exact original data sources based on the data provided at https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13.  

## Data dictionary

- Unable to locate. 
- It seems like the [3 datasets](https://github.com/rfordatascience/tidytuesday/tree/master/data/2018) are a compilation of variuous aggregate data sources from [Our World in Data](https://ourworldindata.org/malaria#data-sources), which, in turn, used data from various other online sources such as the [World Health Organisation](https://apps.who.int/gho/data/node.main.A1367?lang=en) and [Institute of Health Metrics and Evaluation (IHME), Global Burden of Disease (GBD)](http://ghdx.healthdata.org/gbd-results-tool).   

## Dataset limitations  

- The current limitations of this dataset (and this current analyses) are related to the data sources. Since the original data dictionary and original raw data sources was unable to be determined, we had to make assumptions on the representation of the values in the dataset.  

## Assumptions in current analyses 

- Assumptions in this current analysis
  - Deaths are attributed to malaria, 
  
  - The 'Code' variable in the datasets represent the [3 letter ISO 3166-1 alpha-3 country code](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3),  
  
  - SDI refers to ['Socio-demographic Index'](http://ghdx.healthdata.org/record/ihme-data/gbd-2015-socio-demographic-index-sdi-1980%E2%80%932015), which is a summary measure of a geography's socio-demographic development. It is based on average income per person, educational attainment, and total fertility rate (TFR).
  
  - [Malaria incidence rate (per 1 000 population at risk)](https://www.who.int/data/gho/indicator-metadata-registry/imr-details/4670): refers to the number of malaria cases per 1000 population at risk per year. Population at risk is defined as population living in arease where malaria transmission occurs.  
  
  - The composite variables/metrics in the current datasets, `'Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)'` and `'Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)'`, were calculated with minimal error and are an accurate representation of the age-standardised malaria death rate (per 100,000 people) and malaria incidence (per 1,000 people) per year respectively.   
  
  - The baseline population estimates used for the calculation of composite metrics `'Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)'` and `'Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)'` were based on the same population estimates for that particular entity/country for that particular year 
  

## Limitations of current analyses 

- An important limitation of the current analyses is that the original data sources were not able to be cross-validated. 

- Any preprocessing steps done prior to the 3 datasets retrieved from the [Github repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13) are also not known. 

- The definitions of malaria, case incidence of malaria and deaths attributable to malaria is also not known.   

- More importantly, the exact calculation of the composite metrics `'Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)'` and `'Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)'` is not known, and therefore it would be difficult to estimate or quantify the errors contained within this analysis.  

In light of the limitations of the current analyses, statistical testing in this current analyses might lead to erroneous conclusions. This would be due to the lack of validation of the original data sources as well as the lack of understanding on how the composite metrics were determined. Statistical testing would therefore not be conducted for this current analyses.  

---

# Import libraries 

```{r}
library(dplyr)
```

# Import datasets

```{r}
# working directory is the root folder of the Github repo
deaths<- read.csv(
  '../data/malaria_deaths.csv', 
  na.strings=c("NA","NaN", " ", "")
)
deaths_age<-read.csv(
  '../data/malaria_deaths_age.csv', 
  na.strings=c("NA","NaN", " ", "")
)
inc<-read.csv(
  '../data/malaria_inc.csv', 
  na.strings=c("NA","NaN", " ", "")
)
```

# Define functions 

```{r}
# set_entity_type: function to set the entity_type based on multiple conditions: 
# if entity is 'World', set entity_type to 'World, 
# if code is not na, set entity_type to 'Country',
# if code is na and entity contains the characters 'SDI', set entity_type as 'SDI',
# if code is na and entity contains a list of income/demographic terms, set entity)type as 'Income/Demographic'

set_entity_type <- function(df, income_demo) {
  
  df <- df  %>% mutate(entity_type = case_when(
    
    df$entity == 'World' ~ 'World',
    !is.na(df$code) ~ 'Country',
    is.na(df$code) & grepl('SDI', df$entity) ~ 'SDI',
    is.na(df$code) & df$entity %in% income_demo ~ 'Income/Demographic',
    TRUE ~ 'Region' # else statement
  ))
  
  return(df)
}

# set_uk_code: function to set code as 'GBR' if code is na and if the entity contains the terms in uk_entity list
set_uk_code <- function(df, uk_entity) {
  
  df[(is.na(df$code)) & (df$entity %in% uk_entity), 
     "code"] <- 'GBR'
  
  return(df)
}
```


```{r}
# set variables to be used by the functions 
uk_entity <- c(
  'Wales', 
  'England', 
  'Scotland', 
  'Northern Ireland', 
  'United Kingdom'
)

income_demo <- c(
    'Fragile and conflict affected situations',
    'Heavily indebted poor countries (HIPC)',
    'Late-demographic dividend',
    'Least developed countries: UN classification',
    'Low & middle income', 
    'Low income', 
    'Lower middle income',
    'Middle income',
    'Pre-demographic dividend',
    'Upper middle income'
)
```

# Data preprocessing steps:

## **malaria_deaths.csv -> malaria_processed_deaths.csv: `deaths`**

- Tidy up column names:
  - lowercase all column names
  - renamed column name for `'Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)'` to `'age_std_death_rate'`  
  
- Impute the missing `'Code'` values for 'Wales', 'England', 'Scotland', 'Northern Ireland' as 'GBR' as they represent the same geographic region of the United Kingdom   

- Add a new column `'entity_type'` to allow subsetting of entity types:  
  - `'Region'` : aggregated geographic regions, 
  - `'SDI`: Socio-demographic Index status  
  - `'Country'`: entities with non-NA `'Code'` values  
  - `'World'`: global aggregate, as indicated by entity value == 'World' 
  
```{r}

# lowercase column names
names(deaths) <- tolower(names(deaths))

# shorten column name (4th column)
colnames(deaths)[4] <- "age_std_death_rate"

# assign 'GBR' code to uk entities
deaths<- set_uk_code(deaths, uk_entity)
  
# set entity_types
deaths<- set_entity_type(deaths, income_demo)

```


## **malaria_deaths_age.csv -> malaria_deaths_age_processed.csv: `deaths_age`**  

- Drop the row index column `'Unnamed: 0'` as it does not provide any useful information.  

- Impute the missing `'Code'` values for 'Wales', 'England', 'Scotland', 'Northern Ireland' as 'GBR' as they represent the same geographic region of the United Kingdom   

- Add a new column `'entity_type'` to allow subsetting of entity types:  
  - `'Region'` : aggregated geographic regions, 
  - `'SDI`: Socio-demographic Index status  
  - `'Country'`: entities with non-NA `'Code'` values  
  - `'World'`: global aggregate, as indicated by entity value == 'World' 

```{r}
# drop row index
deaths_age <- subset(deaths_age, select = -c(X))

# assign 'GBR' code to uk entities
deaths_age<- set_uk_code(deaths_age, uk_entity)
  
# set entity_types
deaths_age<- set_entity_type(deaths_age, income_demo)

```

## **malaria_inc.csv -> malaria_inc_processed.csv: `inc`**  

- Tidy up column names:
  - lowercase all column names
  - rename column name for `'Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)'` to `'malaria_incidence_1000'` 
  
- Add a new column `'entity_type'` to allow subsetting of entity types:  
  - `'Region'` : aggregated geographic regions, 
  - `'Country'`: entities with non-NA `'Code'` values,
  - `'World'`: global aggregate, as indicated by entity value == 'World', 
  - `'Income/Demographic`: grouping by income or demographic status. These are entities that contain the following terms: 
    - 'Fragile and conflict affected situations',
    - 'Heavily indebted poor countries (HIPC)',
    - 'Late-demographic dividend',
    - 'Least developed countries: UN classification',
    - 'Low & middle income', 
    - 'Low income', 
    - 'Lower middle income',
    - 'Middle income',
    - 'Pre-demographic dividend',
    - 'Upper middle income'

```{r}

# lowercase column names
names(inc) <- tolower(names(inc))

# shorten column name (4th column)
colnames(inc)[4] <- "malaria_incidence_1000"

# assign 'GBR' code to uk entities
inc<- set_uk_code(inc, uk_entity)
  
# set entity_types
inc<- set_entity_type(inc, income_demo)
```

```{r}
# save as csv files 
write.csv(deaths, '../data/processed/R/malaria_deaths_processed.csv', row.names = FALSE)
write.csv(deaths_age, '../data/processed/R/malaria_deaths_age_processed.csv', row.names = FALSE)
write.csv(inc, '../data/processed/R/malaria_inc_processed.csv', row.names = FALSE)
```

# Convert to a R pipeline 

## Define all required functions 

### read csv from url

```{r}
# read csv from github url stated in the configuration file

read_csv_from_url<- function(url) {
  
  tryCatch(
    expr = {
      
      dataframe<- read.csv(
        url, 
        na.strings=c("NA","NaN", " ", "")
      )
      
      message(paste('Successfully read csv from url: ', url))
      
      return(dataframe)
    },
    error = function(e){ 
      
      message(paste('Error reading csv from url: ', url))
      
    }
  )
}
```

### Preprocessing functions

#### helper functions 

```{r}
# set_entity_type: function to set the entity_type based on multiple conditions: 
# if entity is 'World', set entity_type to 'World, 
# if code is not na, set entity_type to 'Country',
# if code is na and entity contains the characters 'SDI', set entity_type as 'SDI',
# if code is na and entity contains a list of income/demographic terms, set entity)type as 'Income/Demographic'

set_entity_type <- function(dataframe, income_demo) {
  
  dataframe <- dataframe  %>% mutate(entity_type = case_when(
    
    dataframe$entity == 'World' ~ 'World',
    !is.na(dataframe$code) ~ 'Country',
    is.na(dataframe$code) & grepl('SDI', dataframe$entity) ~ 'SDI',
    is.na(dataframe$code) & dataframe$entity %in% income_demo ~ 'Income/Demographic',
    TRUE ~ 'Region' # else statement
  ))
  
  return(dataframe)
}

# set_uk_code: function to set code as 'GBR' if code is na and if the entity contains the terms in uk_entity list
set_uk_code <- function(dataframe, uk_entity) {
  
  dataframe[(is.na(dataframe$code)) & (dataframe$entity %in% uk_entity), 
     "code"] <- 'GBR'
  
  return(dataframe)
}

# rename specific column names
rename_specific_cols<- function(dataframe){
  
  if (
    'deaths...malaria...sex..both...age..age.standardized..rate...per.100.000.people.' %in% colnames(dataframe)
    ) {
    
    dataframe <- rename(
      dataframe, 
      age_std_death_rate = deaths...malaria...sex..both...age..age.standardized..rate...per.100.000.people.
    )
  }
  
  else if (
    'incidence.of.malaria..per.1.000.population.at.risk...per.1.000.population.at.risk.' %in% colnames(dataframe)
  ) {
    dataframe <- rename(
      dataframe,
      malaria_incidence_1000 = incidence.of.malaria..per.1.000.population.at.risk...per.1.000.population.at.risk.
    )
  }
  
  return (dataframe)
  
}

# drop row index if present 
drop_row_index <-function(dataframe){
  
  if ('X' %in% colnames(dataframe)){
    
    dataframe <- subset(dataframe, select = -c(X))
    
  }
  return(dataframe)
}
```

#### main preprocessing function to preprocess the 3 dataframes

```{r}
preprocess<- function(dataframe){
  
  clean_dataframe<- dataframe %>%
    drop_row_index() %>%
    rename_all(tolower) %>%
    rename_specific_cols() %>%
    set_uk_code(., uk_entity) %>%
    set_entity_type(., income_demo)
  
  return(clean_dataframe)
}

```

##### Checking preprocess function on deaths dataframe  

```{r}
deaths_clean<-preprocess(deaths)

str(deaths_clean)

# Checking that column values have not been inadvertently altered in the pipe

cat('\nAre the "entity" column values identical in the cleaned and original dataframes?')
identical(
  deaths_clean[['entity']], 
  deaths[['Entity']]
)

cat('\nNumber of rows with code GBR and their entity names:\n')

deaths_clean %>% 
  filter(code == 'GBR') %>%
  select(c(code, entity)) %>%
  table()

cat('\nAre the "year" column values identical in the cleaned and original dataframes?')
identical(
  deaths_clean[['year']], 
  deaths[['Year']]
)

cat('\nAre the "age_std_death_rate" column values identical in the cleaned and original dataframes?')
identical(
  deaths_clean[['age_std_death_rate']], 
  deaths[['Deaths...Malaria...Sex..Both...Age..Age.standardized..Rate...per.100.000.people.']]
)

cat('\nNumber of rows for each entity_type:\n')
table(deaths_clean['entity_type'])

```

##### Checking preprocess function on deaths_age dataframe  

```{r}

deaths_age_clean<-preprocess(deaths_age)

str(deaths_age_clean)

# Checking that column values have not been inadvertently altered in the pipe

cat('\nAre the "entity" column values identical in the cleaned and original dataframes?')
identical(
  deaths_age_clean[['entity']], 
  deaths_age[['entity']]
)

cat('\nNumber of rows with code GBR and their entity names:\n')
deaths_age_clean %>% 
  filter(code == 'GBR') %>%
  select(c(code, entity)) %>%
  table()

cat('\nAre the "year" column values identical in the cleaned and original dataframes?')
identical(
  deaths_age_clean[['year']], 
  deaths_age[['year']]
)

cat('\nNumber of rows for each age group:\n')
table(deaths_age_clean['age_group'])

cat('\nNumber of rows for each entity_type:\n')
table(deaths_age_clean['entity_type'])

```

##### Checking preprocess function on inc dataframe    
  
```{r}
inc_clean<- preprocess(inc)

str(inc_clean)

# Checking that column values have not been inadvertently altered in the pipe

cat('\nAre the "entity" column values identical in the cleaned and original dataframes?')
identical(
  inc_clean[['entity']], 
  inc[['Entity']]
)

cat('\nAre the "code" column values identical in the cleaned and original dataframes?')
identical(
  inc_clean[['code']], 
  inc[['Code']]
)

cat('\nAre the "year" column values identical in the cleaned and original dataframes?')
identical(
  inc_clean[['year']], 
  inc[['Year']]
)

cat('\nAre the "malaria_incidence_1000" column values identical in the cleaned and original dataframes?')
identical(
  inc_clean[['malaria_incidence_1000']], 
  inc[['Incidence.of.malaria..per.1.000.population.at.risk...per.1.000.population.at.risk.']]
)

cat('\nNumber of rows for each entity_type:\n')
table(inc_clean['entity_type'])

```


# Main function to run pipeline functions

## Install packages if required, then load libraries 

```{r}
# Check if required packages are in the list of installed packages. if not, to install the new packages. 

list_of_packages <- c("dplyr")
new_packages <- list_of_packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)

library(dplyr)

## Load configuration variables 
source("../config/config.R")

```

## read csv files from url

```{r}

main<- function(){
  
  # read csv files from urls stated in configuration files 
  deaths<- read_csv_from_url(deaths_url)
  deaths_age<- read_csv_from_url(deaths_age_url)
  inc<- read_csv_from_url(inc_url)
  
  deaths<-preprocess(deaths)
  deaths_age<-preprocess(deaths_age)
  inc<-preprocess(inc)
  
  # save as csv files 
  write.csv(deaths, clean_deaths_path, row.names = FALSE)
  write.csv(deaths_age, clean_deaths_age_path, row.names = FALSE)
  write.csv(inc, clean_inc_path, row.names = FALSE)
  
}

```

```{r}
# if (!interactive()) {
#  main()
#}
```

